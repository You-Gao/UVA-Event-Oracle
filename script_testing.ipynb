{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open ('sites.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "f.close()\n",
    "\n",
    "# manual div class keywords\n",
    "keywords = [\"event\", \"content\", \"detail\", \"card\", \"views\",\"location\",\"time\", \"date\", \"notes\", \"evt\"]\n",
    "\n",
    "# previous 10 years\n",
    "years = [str(i) for i in range(2010, 2024)]\n",
    "\n",
    "# all monnth in title case\n",
    "old_months = [\"January\", \"February\", \"March\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom HTML Parsing as solution vs. LLM Text Extraction w/ HTML Filtering\n",
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\"\"\"\n",
    "1. Retrieve HTML from a site\n",
    "1.1 Retrieve HTML from a site using Selenium\n",
    "2. Extract event text from HTML\n",
    "2.5 Preprocess Event Text\n",
    "3. Store event text in a file\n",
    "4. Convert to JSON or CSV via LLM\n",
    "5. Store in a database\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1 - Retrieve HTML from a site\n",
    "def get_html(site):\n",
    "    response = requests.get(site)\n",
    "    if response is None:\n",
    "        print('Failed to retrieve html from site')\n",
    "        return None\n",
    "    return response.text\n",
    "\n",
    "# 1.1 - Retrieve HTML from a site using Selenium\n",
    "def get_html_selenium(site):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(site)\n",
    "    element = None\n",
    "    # Library Calendar: 4\n",
    "    if \"lib\" in site:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"s-lc-mc-evt\"))\n",
    "        )\n",
    "\n",
    "    # Battern  Calendar: 9\n",
    "    elif \"batten\" in site:\n",
    "        print(\"Batten\")\n",
    "        iframe_id = \"spud913f6613-59b3-4547-ba85-97693a7c9dbb.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        time.sleep(5)\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    # University Calendar: 1\n",
    "    elif \"virginia.edu/calendar\" in site:\n",
    "        print('Virginia')\n",
    "        iframe_id = \"trumba.spud.5.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2 - Extract event text from HTML\n",
    "def extract_event_text(soup):\n",
    "    all_divs = soup.find_all('div')\n",
    "    lowercase_all_divs_classes(all_divs)\n",
    "    event_divs = filter_event_divs(all_divs)\n",
    "    event_text = extract_text_from_event_divs(event_divs)\n",
    "    return event_text\n",
    "\n",
    "# 2.5 - Preprocess Event Text\n",
    "def lowercase_all_divs_classes(divs):\n",
    "    for div in divs:\n",
    "        if div.has_attr('class'):\n",
    "            div['class'] = [x.lower() for x in div['class']]\n",
    "\n",
    "def filter_event_divs(all_divs):\n",
    "    event_divs = []\n",
    "    for div in all_divs:\n",
    "        if div.get('class') is not None and any(keyword in div.get('class')[0] for keyword in keywords):\n",
    "            event_divs.append(div)\n",
    "    return event_divs\n",
    "\n",
    "def extract_text_from_event_divs(event_divs):\n",
    "    event_text = []\n",
    "    for div in event_divs:\n",
    "        text = div.get_text()\n",
    "        text = [x for x in text.split('\\n') if x != '']\n",
    "        for line in text:\n",
    "            if is_old_event(line):\n",
    "                continue\n",
    "            while '\\n' in line:\n",
    "                line = line.replace('\\n', ' ')\n",
    "            event_text.append(line + '\\n')\n",
    "    return event_text\n",
    "\n",
    "\n",
    "def is_old_event(line):\n",
    "    if any(year in line for year in years):\n",
    "        return True\n",
    "    elif any(month in line for month in old_months):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_duplicates(event_text):\n",
    "    return list(set(event_text))\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 3 - Store event text in a file\n",
    "def write_event_text(event_text, filename):\n",
    "    event_text = [x.encode('ascii', 'ignore').decode('ascii') for x in event_text]\n",
    "    folder = \"extracted_txt\"\n",
    "    file_path = folder + \"/\" + filename\n",
    "    with open(file_path, 'w') as f:\n",
    "        for event in event_text:\n",
    "            if len(event) > 0 or event != ' ':\n",
    "                f.write(event)\n",
    "    f.close()\n",
    "    return 0\n",
    "\n",
    "# 4 - Convert to JSON or CSV via LLM\n",
    "def convert_to_json(event_text):\n",
    "    # TODO: call LLM API or make one\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "def single_site(site):\n",
    "    html = get_html_selenium(site)\n",
    "    print(html)\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    event_text = extract_event_text(soup)\n",
    "    write_event_text(event_text, 'site.txt')\n",
    "    \n",
    "    print(len(event_text))\n",
    "    print(event_text)\n",
    "    return 0\n",
    "\n",
    "def main():\n",
    "    for i, site in enumerate(lines):\n",
    "        if i == 1 or i == 4 or i == 9:\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "        event_text = extract_event_text(soup)\n",
    "        write_event_text(event_text, f'site_{i}.txt')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia\n",
      "Found IFRAME\n",
      "Batten\n",
      "Found IFRAME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer, T5ForConditionalGeneration\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mConvert this text to JSON for events with this schema: \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mEvent:\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m- ID: Unique identifier for the event (Integer)\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m- Guest Speaker: The person or organization responsible for the event (String)\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1412\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1412\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1400\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1398\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "input_text = \"\"\"Convert this text to JSON for events with this schema: \n",
    "Event:\n",
    "- ID: Unique identifier for the event (Integer)\n",
    "- Title: The name of the event (String)\n",
    "- Description: Detailed information about the event (String)\n",
    "- Start Time: The date and time when the event starts (DateTime)\n",
    "- End Time: The date and time when the event ends (DateTime)\n",
    "- Location: Where the event takes place (String)\n",
    "- Organizer: The person or organization responsible for the event (String)\n",
    "- Guest Speaker: The person or organization responsible for the event (String)\n",
    "\"\"\"\n",
    "with open('site.txt') as f:\n",
    "    site_text = f.read()\n",
    "f.close()\n",
    "input_text += site_text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parsings(sites):\n",
    "    for id, site in enumerate(sites):\n",
    "        if id == 1 or id == 4 or id == 9:\n",
    "            print(site)\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        if html is not None:\n",
    "            soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "            event_text = extract_event_text(soup)\n",
    "            print(len(event_text), site)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 https://scholarslab.lib.virginia.edu/events/\n",
      "https://www.virginia.edu/calendar\n",
      "Virginia\n",
      "Found IFRAME\n",
      "33 https://www.virginia.edu/calendar\n",
      "595 https://education.virginia.edu/events\n",
      "88 https://global.virginia.edu/events\n",
      "https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "57 https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "1152 https://engineering.virginia.edu/news-events/events\n",
      "24 https://commcal.mcintire.virginia.edu/\n",
      "22 https://www.arch.virginia.edu/events?search=&start=&end=&range=upcoming&events=&pageindex=1&pagesize=12\n",
      "135 https://news.med.virginia.edu/\n",
      "https://events.batten.virginia.edu/\n",
      "Batten\n",
      "Found IFRAME\n",
      "19 https://events.batten.virginia.edu/\n",
      "986 https://economics.virginia.edu/calendar/month?date=2024-04\n",
      "436 https://career.virginia.edu/Employers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parsings(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open ('sites.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "f.close()\n",
    "\n",
    "# manual div class keywords\n",
    "keywords = [\"event\", \"content\", \"detail\", \"card\", \"views\",\"location\",\"time\", \"date\", \"notes\", \"evt\"]\n",
    "\n",
    "# previous 10 years\n",
    "years = [str(i) for i in range(2010, 2024)]\n",
    "\n",
    "# all monnth in title case\n",
    "old_months = [\"January\", \"February\", \"March\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom HTML Parsing as solution vs. LLM Text Extraction w/ HTML Filtering\n",
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\"\"\"\n",
    "1. Retrieve HTML from a site\n",
    "1.1 Retrieve HTML from a site using Selenium\n",
    "2. Extract event text from HTML\n",
    "2.5 Preprocess Event Text\n",
    "3. Store event text in a file\n",
    "4. Convert to JSON or CSV via LLM\n",
    "5. Store in a database\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1 - Retrieve HTML from a site\n",
    "def get_html(site):\n",
    "    response = requests.get(site)\n",
    "    if response is None:\n",
    "        print('Failed to retrieve html from site')\n",
    "        return None\n",
    "    return response.text\n",
    "\n",
    "# 1.1 - Retrieve HTML from a site using Selenium\n",
    "def get_html_selenium(site):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(site)\n",
    "    element = None\n",
    "    # Library Calendar: 4\n",
    "    if \"lib\" in site:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"s-lc-mc-evt\"))\n",
    "        )\n",
    "\n",
    "    # Battern  Calendar: 9\n",
    "    elif \"batten\" in site:\n",
    "        print(\"Batten\")\n",
    "        iframe_id = \"spud913f6613-59b3-4547-ba85-97693a7c9dbb.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        time.sleep(5)\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    # University Calendar: 1\n",
    "    elif \"virginia.edu/calendar\" in site:\n",
    "        print('Virginia')\n",
    "        iframe_id = \"trumba.spud.5.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2 - Extract event text from HTML\n",
    "def extract_event_text(soup):\n",
    "    all_divs = soup.find_all('div')\n",
    "    lowercase_all_divs_classes(all_divs)\n",
    "    event_divs = filter_event_divs(all_divs)\n",
    "    event_text = extract_text_from_event_divs(event_divs)\n",
    "    return event_text\n",
    "\n",
    "# 2.5 - Preprocess Event Text\n",
    "def lowercase_all_divs_classes(divs):\n",
    "    for div in divs:\n",
    "        if div.has_attr('class'):\n",
    "            div['class'] = [x.lower() for x in div['class']]\n",
    "\n",
    "def filter_event_divs(all_divs):\n",
    "    event_divs = []\n",
    "    for div in all_divs:\n",
    "        if div.get('class') is not None and any(keyword in div.get('class')[0] for keyword in keywords):\n",
    "            event_divs.append(div)\n",
    "    return event_divs\n",
    "\n",
    "def extract_text_from_event_divs(event_divs):\n",
    "    event_text = []\n",
    "    for div in event_divs:\n",
    "        text = div.get_text()\n",
    "        text = [x for x in text.split('\\n') if x != '']\n",
    "        for line in text:\n",
    "            if is_old_event(line):\n",
    "                continue\n",
    "            while '\\n' in line:\n",
    "                line = line.replace('\\n', ' ')\n",
    "            event_text.append(line + '\\n')\n",
    "    return event_text\n",
    "\n",
    "\n",
    "def is_old_event(line):\n",
    "    if any(year in line for year in years):\n",
    "        return True\n",
    "    elif any(month in line for month in old_months):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_duplicates(event_text):\n",
    "    return list(set(event_text))\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 3 - Store event text in a file\n",
    "def write_event_text(event_text, filename):\n",
    "    event_text = [x.encode('ascii', 'ignore').decode('ascii') for x in event_text]\n",
    "    folder = \"extracted_txt\"\n",
    "    file_path = folder + \"/\" + filename\n",
    "    with open(file_path, 'w') as f:\n",
    "        for event in event_text:\n",
    "            if len(event) > 0 or event != ' ':\n",
    "                f.write(event)\n",
    "    f.close()\n",
    "    return 0\n",
    "\n",
    "# 4 - Convert to JSON or CSV via LLM\n",
    "def convert_to_json(event_text):\n",
    "    # TODO: call LLM API or make one\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "def single_site(site):\n",
    "    html = get_html_selenium(site)\n",
    "    print(html)\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    event_text = extract_event_text(soup)\n",
    "    write_event_text(event_text, 'site.txt')\n",
    "    \n",
    "    print(len(event_text))\n",
    "    print(event_text)\n",
    "    return 0\n",
    "\n",
    "def main():\n",
    "    for i, site in enumerate(lines):\n",
    "        if i == 1 or i == 4 or i == 9:\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "        event_text = extract_event_text(soup)\n",
    "        write_event_text(event_text, f'site_{i}.txt')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia\n",
      "Found IFRAME\n",
      "Batten\n",
      "Found IFRAME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Convert this text to JSON for events with this schema: \n",
    "Event:\n",
    "- ID: Unique identifier for the event (Integer)\n",
    "- Title: The name of the event (String)\n",
    "- Description: Detailed information about the event (String)\n",
    "- Start Time: The date and time when the event starts (DateTime)\n",
    "- End Time: The date and time when the event ends (DateTime)\n",
    "- Location: Where the event takes place (String)\n",
    "- Organizer: The person or organization responsible for the event (String)\n",
    "- Guest Speaker: The person or organization responsible for the event (String)\n",
    "\"\"\"\n",
    "with open('extracted_txt/site_1.txt') as f:\n",
    "    site_text = f.read()\n",
    "f.close()\n",
    "input_text += site_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Convert this text to JSON for events with this schema: \\nEvent:\\n- ID: Unique identifier for the event (Integer)\\n- Title: The name of the event (String)\\n- Description: Detailed information about the event (String)\\n- Start Time: The date and time when the event starts (DateTime)\\n- End Time: The date and time when the event ends (DateTime)\\n- Location: Where the event takes place (String)\\n- Organizer: The person or organization responsible for the event (String)\\n- Guest Speaker: The person or organization responsible for the event (String)\\nEvents\\nCurrent and past events hosted, sponsored, or partnered on by the Scholars' Lab.\\nUpcoming Events\\nApr17\\nMake a leather book cover\\nWhen: Wednesday, April 17, 2024, 1:00PM-3:00PM\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay3\\nMay the 4th\\nWhen: Friday, May 3, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay6\\nMother's Day\\nWhen: Monday, May 6, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\n \\nPrevious Events\\n2024\\nMake a Website (Wednesday, April 3, 2024)\\nApril Fools' Make-a-Prank (Monday, April 1, 2024)\\n \\nEvents\\nCurrent and past events hosted, sponsored, or partnered on by the Scholars' Lab.\\nUpcoming Events\\nApr17\\nMake a leather book cover\\nWhen: Wednesday, April 17, 2024, 1:00PM-3:00PM\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay3\\nMay the 4th\\nWhen: Friday, May 3, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay6\\nMother's Day\\nWhen: Monday, May 6, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\n \\nPrevious Events\\n2024\\nMake a Website (Wednesday, April 3, 2024)\\nApril Fools' Make-a-Prank (Monday, April 1, 2024)\\nUpcoming Events\\nApr17\\nMake a leather book cover\\nWhen: Wednesday, April 17, 2024, 1:00PM-3:00PM\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay3\\nMay the 4th\\nWhen: Friday, May 3, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay6\\nMother's Day\\nWhen: Monday, May 6, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nApr17\\nMake a leather book cover\\nWhen: Wednesday, April 17, 2024, 1:00PM-3:00PM\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nWhen: Wednesday, April 17, 2024, 1:00PM-3:00PM\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay3\\nMay the 4th\\nWhen: Friday, May 3, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nWhen: Friday, May 3, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\nMay6\\nMother's Day\\nWhen: Monday, May 6, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nWhen: Monday, May 6, 2024, -\\nWhere: Scholars' Lab Makerspace - Alderman 308i\\nDetails \\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "import pathlib\n",
    "import textwrap\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "# call genai with the api key\n",
    "# genai.extract_text_from_image('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> [\n",
       ">   {\n",
       ">     \"ID\": 1,\n",
       ">     \"Title\": \"Facilities Management Apprenticeship & Community Job Fair\",\n",
       ">     \"Description\": \"Join us on April 10 at UVA's Alumni Hall for the annual Apprenticeship Job Fair, featuring UVA FM Apprenticeship and other local employers offering apprenticeships & entry-level positions.\",\n",
       ">     \"Start Time\": \"2024-04-10T09:11:00-04:00\",\n",
       ">     \"End Time\": null,\n",
       ">     \"Location\": \"UVA's Alumni Hall\",\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 2,\n",
       ">     \"Title\": \"In The Frame: Indigenous Vernacular Photography Across Two Continents\",\n",
       ">     \"Description\": \"Join Micheal Aird and Karen Hughes at the Lemon Lounge, 946 Grady Ave, suite 100 for a discussion about how candid and everyday photographs of Indigenous people across multiple communities disrupt assumed settler historical narratives. Aird and Hughes will present their research project that investigates, connects, and exhibits Indigenous community-controlled photography across four communities in Australia and North America.This program will be of interest particularly to community members and people at UVA who wish to work with Indigenous and descendant communities.Michael Aird is a First Nations Australian photographer and curator and director of the University of Queensland Anthropology Museum. He has worked in the area of Aboriginal arts and cultural heritage since 1985 maintaining an interest in documenting aspects of urban Aboriginal history and culture.Karen Hughes is Associate Professor of Indigenous Studies at Swinburne University of Technology. Her research focuses on Indigenous and cross-cultural social and political histories in Australia and North America.\",\n",
       ">     \"Start Time\": \"2024-04-10T14:00:00-04:00\",\n",
       ">     \"End Time\": null,\n",
       ">     \"Location\": \"Lemon Lounge, 946 Grady Ave, suite 100\",\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 3,\n",
       ">     \"Title\": \"M.S. in Commerce Information Session\",\n",
       ">     \"Description\": \"Join us for this information session to learn about the UVA McIntire M.S. in Commerce (MSC) program with tracks in Biotechnology, Business Analytics, Finance, and Marketing & Management. This session will include a comprehensive overview of the academic program, student experience, and career development support as well as an overview of the admissions process and next steps.\",\n",
       ">     \"Start Time\": \"2024-04-10T15:30:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-10T16:30:00-04:00\",\n",
       ">     \"Location\": null,\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 4,\n",
       ">     \"Title\": \"Morven Student Days\",\n",
       ">     \"Description\": \"UVA students are invited to explore, experience, and enjoy Morvens unique landscape!From 10am-4pm, we invite you to use our indoor and outdoor spaces to study and relax, enjoy Arepas food truck, therapy dogs, and more!These spaces include our Formal Garden, Main House, beautiful historic buildings, and more!Free transportation from UVA Grounds to Morven available on a first come first serve basis.Visit our website for more details!\",\n",
       ">     \"Start Time\": \"2024-04-11T10:00:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-11T16:00:00-04:00\",\n",
       ">     \"Location\": \"Morven\",\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 5,\n",
       ">     \"Title\": \"CANCELLED - North Grounds E-Bike Demo Day\",\n",
       ">     \"Description\": \"Come test ride a selection of e-bikes to celebrate Earth Month and in preparation for Cville Bike Month in May! If you are curious about switching to this healthy and sustainable mode of transportation, this a great opportunity to test e-bikes before making a commitment.\",\n",
       ">     \"Start Time\": \"2024-04-11T11:00:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-11T14:00:00-04:00\",\n",
       ">     \"Location\": null,\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 6,\n",
       ">     \"Title\": \"Miraculous Objects: Relics and Buddha Images in Xuanzangs Datang Xiyu ji\",\n",
       ">     \"Description\": \"Join in person or online as Professor Deeg of Cardiff University presents on one of the major sources used for the study of early medieval Buddhism: \\\"Record of the Western Regions of the Great Tang\\\" by Chinese monk Xuanzang (600/602-664).The focus has been and still in on the value of the text for archaeology and historical geography: through the information given in the \\\"Record\\\" places and sites linked to the historical Buddha Sakyamuni have been identified and excavated. Much less attention has been given to the narratives recorded or paraphrased by Xuanzang, particularly when they differ from the \\\"standard\\\" versions in extant Indian Buddhist texts. Even less research has been done on the soemtimes quite detailed stories about relics or/and images of the Buddha in different places on the South Asian subcontinent. This talk will discuss and contextualize the cases of the famous Buddha image and relics in the Northwest (Gandhara) and the miraculous Buddha statue in Bodhgaya.\",\n",
       ">     \"Start Time\": \"2024-04-11T12:15:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-11T13:15:00-04:00\",\n",
       ">     \"Location\": null,\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 7,\n",
       ">     \"Title\": \"National defense strategy: Asking what you can do for your country\",\n",
       ">     \"Description\": \"The Commission on the National Defense Strategy is holding public conversations and meeting with senior national security leaders, business leaders, members of Congress, and foreign allies and partners.We invite you to join Commission Chair Jane Harman and Vice Chair Eric Edelman, along with commissioners Tom Mahnken, General Jack Keane, and Mara Rudman, for apublic conversation moderated by Miller Center Director and CEO William Antholis. ONLINE and IN PERSON\",\n",
       ">     \"Start Time\": \"2024-04-11T14:00:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-11T15:00:00-04:00\",\n",
       ">     \"Location\": null,\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 8,\n",
       ">     \"Title\": \"Social Entrepreneurs and Ventures in Food Justice\",\n",
       ">     \"Description\": \"Join us for an insightful panel discussion on food entrepreneurship and waste reduction as part of the annual FEED Week (Food Engagement, Education, and Discussion Week) on Thursday, April 11th at 4pm at Darden - North Grounds, CLA 140. The panel, co-sponsored by Food Assist and Net Impact at Darden, will feature esteemed guests Clara Camber, a UVA alumni at Goodr, and Eric Walter, the owner of Black Bear Composting. are eager to hear your perspectives and experiences regarding the intersection of business and sustainability. These Panelists insights will shed light on the creative strategies employed by businesses on and off grounds to reduce food waste and promote a more sustainable food system. This panel discussion promises to be an enlightening and inspiring event, highlighting the power of entrepreneurship in addressing critical issues within our food system. Attendees will gain valuable insights into the challenges and opportunities surrounding food waste reduction and the role of businesses in driving positive market change in food systems. To reserve a ticket visit: www.eventbrite.com\",\n",
       ">     \"Start Time\": \"2024-04-11T16:00:00-04:00\",\n",
       ">     \"End Time\": \"2024-04-11T18:00:00-04:00\",\n",
       ">     \"Location\": \"Darden - North Grounds, CLA 140\",\n",
       ">     \"Organizer\": null,\n",
       ">     \"Guest Speaker\": null\n",
       ">   },\n",
       ">   {\n",
       ">     \"ID\": 9,\n",
       ">     \"Title\": \"Matthew Olzmann Poetry Reading\",\n",
       ">     \"Description\": \"Matthew Olzmann reads from his work as part of his time at UVA as a Rea Visiting Writer in Poetry. Olzmann is the author of Constellation Route as well as two previous collections of poetry: Mezzanines and Contradictions in the Design. A recipient of fellowships from Kundiman, MacDowell, and the National Endowment for the Arts, Olmanns poems have appeared in the New York Times, Best American Poetry, the Pushcart Prizes, Kenyon Review, and elsewhere. He is a"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\initializers\\initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to convert output to PyTorch tensors format, PyTorch is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     20\u001b[0m input_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m site_text\n\u001b[1;32m---> 21\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m     22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2872\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2872\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2978\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2959\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2960\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2976\u001b[0m     )\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2996\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3051\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3041\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3043\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3044\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3048\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3049\u001b[0m )\n\u001b[1;32m-> 3051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils.py:722\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    719\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[0;32m    720\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecond_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3541\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.prepare_for_model\u001b[1;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m   3538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_length:\n\u001b[0;32m   3539\u001b[0m     encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 3541\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\n\u001b[0;32m   3543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_outputs\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:224\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    220\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\djx3rn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:713\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tensor_type \u001b[38;5;241m==\u001b[39m TensorType\u001b[38;5;241m.\u001b[39mPYTORCH:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 713\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to convert output to PyTorch tensors format, PyTorch is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     is_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_tensor\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to convert output to PyTorch tensors format, PyTorch is not installed."
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parsings(sites):\n",
    "    for id, site in enumerate(sites):\n",
    "        if id == 1 or id == 4 or id == 9:\n",
    "            print(site)\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        if html is not None:\n",
    "            soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "            event_text = extract_event_text(soup)\n",
    "            print(len(event_text), site)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 https://scholarslab.lib.virginia.edu/events/\n",
      "https://www.virginia.edu/calendar\n",
      "Virginia\n",
      "Found IFRAME\n",
      "33 https://www.virginia.edu/calendar\n",
      "595 https://education.virginia.edu/events\n",
      "88 https://global.virginia.edu/events\n",
      "https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "57 https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "1152 https://engineering.virginia.edu/news-events/events\n",
      "24 https://commcal.mcintire.virginia.edu/\n",
      "22 https://www.arch.virginia.edu/events?search=&start=&end=&range=upcoming&events=&pageindex=1&pagesize=12\n",
      "135 https://news.med.virginia.edu/\n",
      "https://events.batten.virginia.edu/\n",
      "Batten\n",
      "Found IFRAME\n",
      "19 https://events.batten.virginia.edu/\n",
      "986 https://economics.virginia.edu/calendar/month?date=2024-04\n",
      "436 https://career.virginia.edu/Employers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parsings(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

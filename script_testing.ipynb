{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open ('sites.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "f.close()\n",
    "\n",
    "# manual div class keywords\n",
    "keywords = [\"event\", \"content\", \"detail\", \"card\", \"views\",\"location\",\"time\", \"date\", \"notes\", \"evt\"]\n",
    "\n",
    "# previous 10 years\n",
    "years = [str(i) for i in range(2010, 2024)]\n",
    "\n",
    "# all monnth in title case\n",
    "old_months = [\"January\", \"February\", \"March\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom HTML Parsing as solution vs. LLM Text Extraction w/ HTML Filtering\n",
    "import bs4\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\"\"\"\n",
    "1. Retrieve HTML from a site\n",
    "2. Extract event text from HTML\n",
    "2.5 Preprocess Event Text\n",
    "3. Store event text in a file\n",
    "4. Convert to JSON or CSV via LLM\n",
    "5. Store in a database\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1\n",
    "def get_html(site):\n",
    "    response = requests.get(site)\n",
    "    if response is None:\n",
    "        print('Failed to retrieve html from site')\n",
    "        return None\n",
    "    return response.text\n",
    "\n",
    "# 1.1\n",
    "def get_html_selenium(site):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(site)\n",
    "    element = None\n",
    "    # Library Calendar: 4\n",
    "    if \"lib\" in site:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"s-lc-mc-evt\"))\n",
    "        )\n",
    "\n",
    "    # Battern  Calendar: 9\n",
    "    elif \"batten\" in site:\n",
    "        print(\"Batten\")\n",
    "        iframe_id = \"spud913f6613-59b3-4547-ba85-97693a7c9dbb.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        time.sleep(5)\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    # University Calendar: 1\n",
    "    elif \"virginia.edu/calendar\" in site:\n",
    "        print('Virginia')\n",
    "        iframe_id = \"trumba.spud.5.iframe\"\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, iframe_id))\n",
    "        )\n",
    "        driver.switch_to.frame(iframe_id)\n",
    "        print(\"Found IFRAME\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "# 2\n",
    "def extract_event_text(soup):\n",
    "    all_divs = soup.find_all('div')\n",
    "    lowercase_all_divs_classes(all_divs)\n",
    "    event_divs = filter_event_divs(all_divs)\n",
    "    event_text = extract_text_from_event_divs(event_divs)\n",
    "    return event_text\n",
    "\n",
    "# 2.5\n",
    "def lowercase_all_divs_classes(divs):\n",
    "    for div in divs:\n",
    "        if div.has_attr('class'):\n",
    "            div['class'] = [x.lower() for x in div['class']]\n",
    "\n",
    "def filter_event_divs(all_divs):\n",
    "    event_divs = []\n",
    "    for div in all_divs:\n",
    "        if div.get('class') is not None and any(keyword in div.get('class')[0] for keyword in keywords):\n",
    "            event_divs.append(div)\n",
    "    return event_divs\n",
    "\n",
    "def extract_text_from_event_divs(event_divs):\n",
    "    event_text = []\n",
    "    for div in event_divs:\n",
    "        text = div.get_text()\n",
    "        text = [x for x in text.split('\\n') if x != '']\n",
    "        for line in text:\n",
    "            if is_old_event(line):\n",
    "                continue\n",
    "            while '\\n' in line:\n",
    "                line = line.replace('\\n', ' ')\n",
    "            event_text.append(line + '\\n')\n",
    "    return event_text\n",
    "\n",
    "\n",
    "def is_old_event(line):\n",
    "    if any(year in line for year in years):\n",
    "        return True\n",
    "    elif any(month in line for month in old_months):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_duplicates(event_text):\n",
    "    return list(set(event_text))\n",
    "\n",
    "# 3\n",
    "def write_event_text(event_text, filename):\n",
    "    event_text = [x.encode('ascii', 'ignore').decode('ascii') for x in event_text]\n",
    "    folder = \"extracted_txt\"\n",
    "    file_path = folder + \"/\" + filename\n",
    "    with open(file_path, 'w') as f:\n",
    "        for event in event_text:\n",
    "            if len(event) > 0 or event != ' ':\n",
    "                f.write(event)\n",
    "    f.close()\n",
    "    return 0\n",
    "\n",
    "# 4\n",
    "def convert_to_json(event_text):\n",
    "    # TODO: call LLM API or make one\n",
    "    return 0\n",
    "\n",
    "def single_site(site):\n",
    "    html = get_html_selenium(site)\n",
    "    print(html)\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    event_text = extract_event_text(soup)\n",
    "    write_event_text(event_text, 'site.txt')\n",
    "    \n",
    "    print(len(event_text))\n",
    "    print(event_text)\n",
    "    return 0\n",
    "\n",
    "def main():\n",
    "    for i, site in enumerate(lines):\n",
    "        if i == 1 or i == 4 or i == 9:\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "        event_text = extract_event_text(soup)\n",
    "        write_event_text(event_text, f'site_{i}.txt')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia\n",
      "Found IFRAME\n",
      "Batten\n",
      "Found IFRAME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parsings(sites):\n",
    "    for id, site in enumerate(sites):\n",
    "        if id == 1 or id == 4 or id == 9:\n",
    "            print(site)\n",
    "            html = get_html_selenium(site)\n",
    "        else:\n",
    "            html = get_html(site)\n",
    "        if html is not None:\n",
    "            soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "            event_text = extract_event_text(soup)\n",
    "            print(len(event_text), site)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 https://scholarslab.lib.virginia.edu/events/\n",
      "https://www.virginia.edu/calendar\n",
      "Virginia\n",
      "Found IFRAME\n",
      "33 https://www.virginia.edu/calendar\n",
      "595 https://education.virginia.edu/events\n",
      "88 https://global.virginia.edu/events\n",
      "https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "57 https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "1152 https://engineering.virginia.edu/news-events/events\n",
      "24 https://commcal.mcintire.virginia.edu/\n",
      "22 https://www.arch.virginia.edu/events?search=&start=&end=&range=upcoming&events=&pageindex=1&pagesize=12\n",
      "135 https://news.med.virginia.edu/\n",
      "https://events.batten.virginia.edu/\n",
      "Batten\n",
      "Found IFRAME\n",
      "19 https://events.batten.virginia.edu/\n",
      "986 https://economics.virginia.edu/calendar/month?date=2024-04\n",
      "436 https://career.virginia.edu/Employers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parsings(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open ('sites.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "f.close()\n",
    "\n",
    "# manual div class keywords\n",
    "keywords = [\"event\", \"content\", \"views\"]\n",
    "\n",
    "# previous 10 years\n",
    "years = [str(i) for i in range(2010, 2024)]\n",
    "\n",
    "# all monnth in title case\n",
    "old_months = [\"January\", \"February\", \"March\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom HTML Parsing as solution vs. LLM Text Extraction w/ HTML Filtering\n",
    "import bs4\n",
    "\n",
    "\"\"\"\n",
    "1. Retrieve HTML from a site\n",
    "2. Extract event text from HTML\n",
    "2.5 Preprocess Event Text\n",
    "3. Store event text in a file\n",
    "4. Convert to JSON or CSV via LLM\n",
    "5. Store in a database\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1\n",
    "def get_html(site):\n",
    "    import requests\n",
    "    response = requests.get(site)\n",
    "    if response is None:\n",
    "        print('Failed to retrieve html from site')\n",
    "        return None\n",
    "    return response.text\n",
    "\n",
    "# 2\n",
    "def extract_event_text(soup):\n",
    "    all_divs = soup.find_all('div')\n",
    "    lowercase_all_divs_classes(all_divs)\n",
    "    event_divs = filter_event_divs(all_divs)\n",
    "    event_text = extract_text_from_event_divs(event_divs)\n",
    "    return event_text\n",
    "\n",
    "# 2.5\n",
    "def lowercase_all_divs_classes(divs):\n",
    "    for div in divs:\n",
    "        if div.has_attr('class'):\n",
    "            div['class'] = [x.lower() for x in div['class']]\n",
    "\n",
    "def filter_event_divs(all_divs):\n",
    "    event_divs = []\n",
    "    for div in all_divs:\n",
    "        if div.get('class') is not None and any(keyword in div.get('class')[0] for keyword in keywords):\n",
    "            event_divs.append(div)\n",
    "    return event_divs\n",
    "\n",
    "def extract_text_from_event_divs(event_divs):\n",
    "    event_text = []\n",
    "    for div in event_divs:\n",
    "        text = div.get_text()\n",
    "        text = [x for x in text.split('\\n') if x != '']\n",
    "        for line in text:\n",
    "            if is_old_event(line):\n",
    "                continue\n",
    "            while '\\n' in line:\n",
    "                line = line.replace('\\n', ' ')\n",
    "            event_text.append(line + '\\n')\n",
    "    return event_text\n",
    "\n",
    "\n",
    "def is_old_event(line):\n",
    "    if any(year in line for year in years):\n",
    "        return True\n",
    "    elif any(month in line for month in old_months):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_duplicates(event_text):\n",
    "    return list(set(event_text))\n",
    "\n",
    "# 3\n",
    "def write_event_text(event_text, filename):\n",
    "    event_text = [x.encode('ascii', 'ignore').decode('ascii') for x in event_text]\n",
    "    folder = \"extracted_txt\"\n",
    "    file_path = folder + \"/\" + filename\n",
    "    with open(file_path, 'w') as f:\n",
    "        for event in event_text:\n",
    "            if len(event) > 0 or event != ' ':\n",
    "                f.write(event)\n",
    "    f.close()\n",
    "    return 0\n",
    "\n",
    "# 4\n",
    "def convert_to_json(event_text):\n",
    "    # TODO: call LLM API or make one\n",
    "    return 0\n",
    "\n",
    "def single_site(site):\n",
    "    html = get_html(site)\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    event_text = extract_event_text(soup)\n",
    "    write_event_text(event_text, 'site.txt')\n",
    "    \n",
    "    print(len(event_text))\n",
    "    print(event_text)\n",
    "    return 0\n",
    "\n",
    "def main():\n",
    "    for i, site in enumerate(lines):\n",
    "        html = get_html(site)\n",
    "        soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "        event_text = extract_event_text(soup)\n",
    "        write_event_text(event_text, f'site_{i}.txt')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "['Events\\n', \"Current and past events hosted, sponsored, or partnered on by the Scholars' Lab.\\n\", 'Upcoming Events\\n', 'Apr17\\n', 'Make a leather book cover\\n', 'When: Wednesday, April 17, 2024, 1:00PM-3:00PM\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May3\\n', 'May the 4th\\n', 'When: Friday, May 3, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May6\\n', \"Mother's Day\\n\", 'When: Monday, May 6, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', ' \\n', 'Previous Events\\n', '2024\\n', 'Make a Website (Wednesday, April 3, 2024)\\n', \"April Fools' Make-a-Prank (Monday, April 1, 2024)\\n\", ' \\n', 'Events\\n', \"Current and past events hosted, sponsored, or partnered on by the Scholars' Lab.\\n\", 'Upcoming Events\\n', 'Apr17\\n', 'Make a leather book cover\\n', 'When: Wednesday, April 17, 2024, 1:00PM-3:00PM\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May3\\n', 'May the 4th\\n', 'When: Friday, May 3, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May6\\n', \"Mother's Day\\n\", 'When: Monday, May 6, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', ' \\n', 'Previous Events\\n', '2024\\n', 'Make a Website (Wednesday, April 3, 2024)\\n', \"April Fools' Make-a-Prank (Monday, April 1, 2024)\\n\", 'Upcoming Events\\n', 'Apr17\\n', 'Make a leather book cover\\n', 'When: Wednesday, April 17, 2024, 1:00PM-3:00PM\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May3\\n', 'May the 4th\\n', 'When: Friday, May 3, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May6\\n', \"Mother's Day\\n\", 'When: Monday, May 6, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'Apr17\\n', 'Make a leather book cover\\n', 'When: Wednesday, April 17, 2024, 1:00PM-3:00PM\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'When: Wednesday, April 17, 2024, 1:00PM-3:00PM\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May3\\n', 'May the 4th\\n', 'When: Friday, May 3, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'When: Friday, May 3, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n', 'May6\\n', \"Mother's Day\\n\", 'When: Monday, May 6, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'When: Monday, May 6, 2024, -\\n', \"Where: Scholars' Lab Makerspace - Alderman 308i\\n\", 'Details ›\\n']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_site(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parsings(sites):\n",
    "    for site in sites:\n",
    "        html = get_html(site)\n",
    "        if html is not None:\n",
    "            soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "            event_text = extract_event_text(soup)\n",
    "            print(len(event_text), site)\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 https://scholarslab.lib.virginia.edu/events/\n",
      "7 https://www.virginia.edu/calendar\n",
      "22 https://education.virginia.edu/events\n",
      "11 https://global.virginia.edu/events\n",
      "0 https://cal.lib.virginia.edu/calendar/events?cid=4299&t=m&d=0000-00-00&cal=4299&ct=69160,33395,66337,31015,30813,51597,58853,58854,58855,58856,70846,45972,31362,27888,30045,27381,57994,54907,26930,29624,56703,66253,66255,66338,46136,70848,33496,70427,27725,29618,63738,28898,33396,38996,50481,70849,51598,29985&inc=0\n",
      "93 https://engineering.virginia.edu/news-events/events\n",
      "24 https://commcal.mcintire.virginia.edu/\n",
      "1 https://www.arch.virginia.edu/events?search=&start=&end=&range=upcoming&events=&pageindex=1&pagesize=12\n",
      "1 https://news.med.virginia.edu/\n",
      "0 https://events.batten.virginia.edu/\n",
      "117 https://economics.virginia.edu/calendar/month?date=2024-04\n",
      "102 https://career.virginia.edu/Employers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parsings(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
